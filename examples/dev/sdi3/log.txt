model_folder = ./sdi3
model_root = sdi3
data_path = c:/data/sdi3merged.hdf5
idx_in [0, 1, 2, 3, 4, 5]
idx_out [6, 7, 8]
read 296 dataframes
dt=0.001000 data_len=3000 n_io=9 n_case=296
['Fc', 'Ud', 'Uq', 'Rc', 'Vd', 'Vq'] ['Id', 'Iq', 'Idc'] (296, 3000, 9)
shapes of t (3000,) data_train (296, 3000, 9) n_in=6, n_out=3
t range 0.000000 to 2.999000
Before Scaling:
Column       Min       Max      Mean     Range
Fc        58.000    62.000    60.000     4.000
Ud         0.470     0.680     0.606     0.210
Uq         0.000     0.470     0.013     0.470
Rc        21.337   330.000    75.402   308.663
Vd      -442.526  -168.505  -223.891   274.021
Vq       -23.048    23.909     0.139    46.957
Id        -8.908     8.762    -1.957    17.670
Iq        -8.589     6.965    -0.525    15.554
Idc        0.213     3.074     1.694     2.861
After Scaling:
Column       Min       Max      Mean     Range     Scale    Offset
Fc        -0.500     0.500     0.000     1.000     4.000    60.000
Ud        -0.649     0.351     0.000     1.000     0.210     0.606
Uq        -0.027     0.973    -0.000     1.000     0.470     0.013
Rc        -0.175     0.825     0.000     1.000   308.663    75.402
Vd        -0.798     0.202     0.000     1.000   274.021  -223.891
Vq        -0.494     0.506     0.000     1.000    46.957     0.139
Id        -0.393     0.607    -0.000     1.000    17.670    -1.957
Iq        -0.518     0.482     0.000     1.000    15.554    -0.525
Idc       -0.518     0.482     0.000     1.000     2.861     1.694
make_mimo_block iir
Dataset split: 296 246 50 validation_scale=4.920
Epoch    0 of 5000 | Training Loss     0.874130 | Validation Loss     0.833820
Epoch   20 of 5000 | Training Loss     0.220107 | Validation Loss     0.268933
Epoch   40 of 5000 | Training Loss     0.162982 | Validation Loss     0.200433
Epoch   60 of 5000 | Training Loss     0.157302 | Validation Loss     0.199634
Epoch   80 of 5000 | Training Loss     0.159313 | Validation Loss     0.196053
Epoch  100 of 5000 | Training Loss     0.156701 | Validation Loss     0.194569
Epoch  120 of 5000 | Training Loss     0.153553 | Validation Loss     0.188566
Epoch  140 of 5000 | Training Loss     0.157263 | Validation Loss     0.189812
Epoch  160 of 5000 | Training Loss     0.153679 | Validation Loss     0.190782
Epoch  180 of 5000 | Training Loss     0.152994 | Validation Loss     0.193672
Epoch  200 of 5000 | Training Loss     0.156169 | Validation Loss     0.191940
Epoch  220 of 5000 | Training Loss     0.155528 | Validation Loss     0.187119
Epoch  240 of 5000 | Training Loss     0.150803 | Validation Loss     0.189071
Epoch  260 of 5000 | Training Loss     0.157703 | Validation Loss     0.185076
Epoch  280 of 5000 | Training Loss     0.155276 | Validation Loss     0.186015
Epoch  300 of 5000 | Training Loss     0.153535 | Validation Loss     0.185100
Epoch  320 of 5000 | Training Loss     0.153396 | Validation Loss     0.187391
Epoch  340 of 5000 | Training Loss     0.151427 | Validation Loss     0.189655
Epoch  360 of 5000 | Training Loss     0.152617 | Validation Loss     0.189762
Epoch  380 of 5000 | Training Loss     0.152906 | Validation Loss     0.185952
Epoch  400 of 5000 | Training Loss     0.150474 | Validation Loss     0.186180
Epoch  420 of 5000 | Training Loss     0.155566 | Validation Loss     0.187096
Epoch  440 of 5000 | Training Loss     0.150687 | Validation Loss     0.190217
Epoch  460 of 5000 | Training Loss     0.154060 | Validation Loss     0.188318
Epoch  480 of 5000 | Training Loss     0.150939 | Validation Loss     0.190691
Epoch  500 of 5000 | Training Loss     0.150468 | Validation Loss     0.186545
Epoch  520 of 5000 | Training Loss     0.152790 | Validation Loss     0.191266
Epoch  540 of 5000 | Training Loss     0.154579 | Validation Loss     0.183421
Epoch  560 of 5000 | Training Loss     0.151587 | Validation Loss     0.187354
Epoch  580 of 5000 | Training Loss     0.151519 | Validation Loss     0.180860
Epoch  600 of 5000 | Training Loss     0.154067 | Validation Loss     0.187534
Epoch  620 of 5000 | Training Loss     0.153747 | Validation Loss     0.191731
Epoch  640 of 5000 | Training Loss     0.151916 | Validation Loss     0.184037
Epoch  660 of 5000 | Training Loss     0.153529 | Validation Loss     0.184305
Epoch  680 of 5000 | Training Loss     0.155535 | Validation Loss     0.187121
Epoch  700 of 5000 | Training Loss     0.149936 | Validation Loss     0.188327
Epoch  720 of 5000 | Training Loss     0.151433 | Validation Loss     0.181716
Epoch  740 of 5000 | Training Loss     0.149792 | Validation Loss     0.186657
Epoch  760 of 5000 | Training Loss     0.151000 | Validation Loss     0.187875
Epoch  780 of 5000 | Training Loss     0.149708 | Validation Loss     0.189741
Epoch  800 of 5000 | Training Loss     0.148564 | Validation Loss     0.192250
Epoch  820 of 5000 | Training Loss     0.153334 | Validation Loss     0.188816
Epoch  840 of 5000 | Training Loss     0.150495 | Validation Loss     0.183819
Epoch  860 of 5000 | Training Loss     0.150906 | Validation Loss     0.187712
Epoch  880 of 5000 | Training Loss     0.152503 | Validation Loss     0.185863
Epoch  900 of 5000 | Training Loss     0.149414 | Validation Loss     0.189991
Epoch  920 of 5000 | Training Loss     0.148649 | Validation Loss     0.187988
Epoch  940 of 5000 | Training Loss     0.148936 | Validation Loss     0.194264
Epoch  960 of 5000 | Training Loss     0.150677 | Validation Loss     0.184572
Epoch  980 of 5000 | Training Loss     0.148669 | Validation Loss     0.196400
Epoch 1000 of 5000 | Training Loss     0.151729 | Validation Loss     0.186778
Epoch 1020 of 5000 | Training Loss     0.150965 | Validation Loss     0.185929
Epoch 1040 of 5000 | Training Loss     0.148938 | Validation Loss     0.187828
Epoch 1060 of 5000 | Training Loss     0.148429 | Validation Loss     0.189023
Epoch 1080 of 5000 | Training Loss     0.149122 | Validation Loss     0.190306
Epoch 1100 of 5000 | Training Loss     0.150103 | Validation Loss     0.186811
Epoch 1120 of 5000 | Training Loss     0.149415 | Validation Loss     0.189895
Epoch 1140 of 5000 | Training Loss     0.148743 | Validation Loss     0.193982
Epoch 1160 of 5000 | Training Loss     0.149909 | Validation Loss     0.185454
Epoch 1180 of 5000 | Training Loss     0.152129 | Validation Loss     0.189616
Epoch 1200 of 5000 | Training Loss     0.146543 | Validation Loss     0.190433
Epoch 1220 of 5000 | Training Loss     0.153560 | Validation Loss     0.188262
Epoch 1240 of 5000 | Training Loss     0.150942 | Validation Loss     0.190088
Epoch 1260 of 5000 | Training Loss     0.149146 | Validation Loss     0.189507
Epoch 1280 of 5000 | Training Loss     0.148341 | Validation Loss     0.188656
Epoch 1300 of 5000 | Training Loss     0.151709 | Validation Loss     0.190545
Epoch 1320 of 5000 | Training Loss     0.149825 | Validation Loss     0.188572
Epoch 1340 of 5000 | Training Loss     0.151228 | Validation Loss     0.188782
Epoch 1360 of 5000 | Training Loss     0.152534 | Validation Loss     0.186822
Epoch 1380 of 5000 | Training Loss     0.151283 | Validation Loss     0.190121
Epoch 1400 of 5000 | Training Loss     0.151013 | Validation Loss     0.188877
Epoch 1420 of 5000 | Training Loss     0.146343 | Validation Loss     0.191814
Epoch 1440 of 5000 | Training Loss     0.148835 | Validation Loss     0.192239
Epoch 1460 of 5000 | Training Loss     0.146638 | Validation Loss     0.192521
Epoch 1480 of 5000 | Training Loss     0.147208 | Validation Loss     0.188014
Epoch 1500 of 5000 | Training Loss     0.147426 | Validation Loss     0.188247
Epoch 1520 of 5000 | Training Loss     0.147977 | Validation Loss     0.191055
Epoch 1540 of 5000 | Training Loss     0.148178 | Validation Loss     0.190972
Epoch 1560 of 5000 | Training Loss     0.151864 | Validation Loss     0.195241
Epoch 1580 of 5000 | Training Loss     0.147093 | Validation Loss     0.191670
Epoch 1600 of 5000 | Training Loss     0.152322 | Validation Loss     0.196369
Epoch 1620 of 5000 | Training Loss     0.149377 | Validation Loss     0.189335
Epoch 1640 of 5000 | Training Loss     0.150672 | Validation Loss     0.194691
Epoch 1660 of 5000 | Training Loss     0.150444 | Validation Loss     0.190923
Epoch 1680 of 5000 | Training Loss     0.148830 | Validation Loss     0.198559
Epoch 1700 of 5000 | Training Loss     0.148760 | Validation Loss     0.191500
Epoch 1720 of 5000 | Training Loss     0.146788 | Validation Loss     0.192529
Epoch 1740 of 5000 | Training Loss     0.150033 | Validation Loss     0.192586
Epoch 1760 of 5000 | Training Loss     0.147036 | Validation Loss     0.191359
Epoch 1780 of 5000 | Training Loss     0.150270 | Validation Loss     0.193675
Epoch 1800 of 5000 | Training Loss     0.151950 | Validation Loss     0.194406
Epoch 1820 of 5000 | Training Loss     0.150414 | Validation Loss     0.191935
Epoch 1840 of 5000 | Training Loss     0.147636 | Validation Loss     0.195738
Epoch 1860 of 5000 | Training Loss     0.148686 | Validation Loss     0.190862
Epoch 1880 of 5000 | Training Loss     0.146237 | Validation Loss     0.192759
Epoch 1900 of 5000 | Training Loss     0.143878 | Validation Loss     0.193696
Epoch 1920 of 5000 | Training Loss     0.144613 | Validation Loss     0.189539
Epoch 1940 of 5000 | Training Loss     0.144959 | Validation Loss     0.193913
Epoch 1960 of 5000 | Training Loss     0.147652 | Validation Loss     0.195715
Epoch 1980 of 5000 | Training Loss     0.145192 | Validation Loss     0.190791
Epoch 2000 of 5000 | Training Loss     0.150407 | Validation Loss     0.198264
Epoch 2020 of 5000 | Training Loss     0.148230 | Validation Loss     0.193872
Epoch 2040 of 5000 | Training Loss     0.148039 | Validation Loss     0.199241
Epoch 2060 of 5000 | Training Loss     0.146086 | Validation Loss     0.197535
Epoch 2080 of 5000 | Training Loss     0.145418 | Validation Loss     0.200618
Epoch 2100 of 5000 | Training Loss     0.145146 | Validation Loss     0.197152
Epoch 2120 of 5000 | Training Loss     0.145641 | Validation Loss     0.190637
Epoch 2140 of 5000 | Training Loss     0.149476 | Validation Loss     0.193179
Epoch 2160 of 5000 | Training Loss     0.148147 | Validation Loss     0.192508
Epoch 2180 of 5000 | Training Loss     0.146131 | Validation Loss     0.196781
Epoch 2200 of 5000 | Training Loss     0.143782 | Validation Loss     0.198181
Epoch 2220 of 5000 | Training Loss     0.146547 | Validation Loss     0.197643
Epoch 2240 of 5000 | Training Loss     0.146961 | Validation Loss     0.192983
Epoch 2260 of 5000 | Training Loss     0.147147 | Validation Loss     0.198695
Epoch 2280 of 5000 | Training Loss     0.146201 | Validation Loss     0.195044
Epoch 2300 of 5000 | Training Loss     0.144008 | Validation Loss     0.198195
Epoch 2320 of 5000 | Training Loss     0.145568 | Validation Loss     0.198755
Epoch 2340 of 5000 | Training Loss     0.143121 | Validation Loss     0.196594
Epoch 2360 of 5000 | Training Loss     0.144775 | Validation Loss     0.197539
Epoch 2380 of 5000 | Training Loss     0.144546 | Validation Loss     0.196504
Epoch 2400 of 5000 | Training Loss     0.145501 | Validation Loss     0.197789
Epoch 2420 of 5000 | Training Loss     0.150977 | Validation Loss     0.196993
Epoch 2440 of 5000 | Training Loss     0.141815 | Validation Loss     0.201585
Epoch 2460 of 5000 | Training Loss     0.145699 | Validation Loss     0.196547
Epoch 2480 of 5000 | Training Loss     0.146734 | Validation Loss     0.195880
Epoch 2500 of 5000 | Training Loss     0.145017 | Validation Loss     0.202488
Epoch 2520 of 5000 | Training Loss     0.145414 | Validation Loss     0.201254
Epoch 2540 of 5000 | Training Loss     0.143279 | Validation Loss     0.199320
Epoch 2560 of 5000 | Training Loss     0.146501 | Validation Loss     0.196642
Epoch 2580 of 5000 | Training Loss     0.142908 | Validation Loss     0.206164
Epoch 2600 of 5000 | Training Loss     0.148302 | Validation Loss     0.199244
Epoch 2620 of 5000 | Training Loss     0.143446 | Validation Loss     0.200288
Epoch 2640 of 5000 | Training Loss     0.143967 | Validation Loss     0.200526
Epoch 2660 of 5000 | Training Loss     0.145386 | Validation Loss     0.206001
Epoch 2680 of 5000 | Training Loss     0.145472 | Validation Loss     0.204314
Epoch 2700 of 5000 | Training Loss     0.150332 | Validation Loss     0.209405
Epoch 2720 of 5000 | Training Loss     0.147924 | Validation Loss     0.199371
Epoch 2740 of 5000 | Training Loss     0.146166 | Validation Loss     0.212642
Epoch 2760 of 5000 | Training Loss     0.145088 | Validation Loss     0.209634
Epoch 2780 of 5000 | Training Loss     0.139714 | Validation Loss     0.211975
Epoch 2800 of 5000 | Training Loss     0.143008 | Validation Loss     0.208674
Epoch 2820 of 5000 | Training Loss     0.142330 | Validation Loss     0.207897
Epoch 2840 of 5000 | Training Loss     0.145333 | Validation Loss     0.211581
Epoch 2860 of 5000 | Training Loss     0.142095 | Validation Loss     0.208644
Epoch 2880 of 5000 | Training Loss     0.144375 | Validation Loss     0.211596
Epoch 2900 of 5000 | Training Loss     0.143543 | Validation Loss     0.211293
Epoch 2920 of 5000 | Training Loss     0.140297 | Validation Loss     0.210535
Epoch 2940 of 5000 | Training Loss     0.142105 | Validation Loss     0.213992
Epoch 2960 of 5000 | Training Loss     0.140381 | Validation Loss     0.208924
Epoch 2980 of 5000 | Training Loss     0.141823 | Validation Loss     0.210806
Epoch 3000 of 5000 | Training Loss     0.143642 | Validation Loss     0.219987
Epoch 3020 of 5000 | Training Loss     0.140999 | Validation Loss     0.216374
Epoch 3040 of 5000 | Training Loss     0.143481 | Validation Loss     0.214286
Epoch 3060 of 5000 | Training Loss     0.145895 | Validation Loss     0.216491
Epoch 3080 of 5000 | Training Loss     0.137911 | Validation Loss     0.215144
Epoch 3100 of 5000 | Training Loss     0.139873 | Validation Loss     0.223482
Epoch 3120 of 5000 | Training Loss     0.140690 | Validation Loss     0.223078
Epoch 3140 of 5000 | Training Loss     0.139436 | Validation Loss     0.211734
Epoch 3160 of 5000 | Training Loss     0.141009 | Validation Loss     0.216086
Epoch 3180 of 5000 | Training Loss     0.142817 | Validation Loss     0.220623
Epoch 3200 of 5000 | Training Loss     0.142747 | Validation Loss     0.212716
Epoch 3220 of 5000 | Training Loss     0.143348 | Validation Loss     0.218481
Epoch 3240 of 5000 | Training Loss     0.144300 | Validation Loss     0.215255
Epoch 3260 of 5000 | Training Loss     0.139575 | Validation Loss     0.216372
Epoch 3280 of 5000 | Training Loss     0.137841 | Validation Loss     0.219483
Epoch 3300 of 5000 | Training Loss     0.141349 | Validation Loss     0.219899
Epoch 3320 of 5000 | Training Loss     0.138963 | Validation Loss     0.215911
Epoch 3340 of 5000 | Training Loss     0.139533 | Validation Loss     0.223527
Epoch 3360 of 5000 | Training Loss     0.139745 | Validation Loss     0.222708
Epoch 3380 of 5000 | Training Loss     0.138092 | Validation Loss     0.219330
Epoch 3400 of 5000 | Training Loss     0.140435 | Validation Loss     0.213246
Epoch 3420 of 5000 | Training Loss     0.143263 | Validation Loss     0.214330
Epoch 3440 of 5000 | Training Loss     0.137153 | Validation Loss     0.218058
Epoch 3460 of 5000 | Training Loss     0.141092 | Validation Loss     0.217325
Epoch 3480 of 5000 | Training Loss     0.137085 | Validation Loss     0.224742
Epoch 3500 of 5000 | Training Loss     0.140447 | Validation Loss     0.221534
Epoch 3520 of 5000 | Training Loss     0.138845 | Validation Loss     0.218250
Epoch 3540 of 5000 | Training Loss     0.142249 | Validation Loss     0.215519
Epoch 3560 of 5000 | Training Loss     0.139440 | Validation Loss     0.219690
Epoch 3580 of 5000 | Training Loss     0.139424 | Validation Loss     0.213979
Epoch 3600 of 5000 | Training Loss     0.141662 | Validation Loss     0.220132
Epoch 3620 of 5000 | Training Loss     0.136342 | Validation Loss     0.224718
Epoch 3640 of 5000 | Training Loss     0.136856 | Validation Loss     0.212976
Epoch 3660 of 5000 | Training Loss     0.140007 | Validation Loss     0.221788
Epoch 3680 of 5000 | Training Loss     0.135940 | Validation Loss     0.217722
Epoch 3700 of 5000 | Training Loss     0.137194 | Validation Loss     0.218373
Epoch 3720 of 5000 | Training Loss     0.136016 | Validation Loss     0.215902
Epoch 3740 of 5000 | Training Loss     0.138939 | Validation Loss     0.221702
Epoch 3760 of 5000 | Training Loss     0.139061 | Validation Loss     0.219669
Epoch 3780 of 5000 | Training Loss     0.138118 | Validation Loss     0.215913
Epoch 3800 of 5000 | Training Loss     0.137949 | Validation Loss     0.212588
Epoch 3820 of 5000 | Training Loss     0.138766 | Validation Loss     0.219885
Epoch 3840 of 5000 | Training Loss     0.135921 | Validation Loss     0.214262
Epoch 3860 of 5000 | Training Loss     0.133734 | Validation Loss     0.223400
Epoch 3880 of 5000 | Training Loss     0.134962 | Validation Loss     0.225454
Epoch 3900 of 5000 | Training Loss     0.137273 | Validation Loss     0.218717
Epoch 3920 of 5000 | Training Loss     0.139524 | Validation Loss     0.215544
Epoch 3940 of 5000 | Training Loss     0.136287 | Validation Loss     0.223936
Epoch 3960 of 5000 | Training Loss     0.135433 | Validation Loss     0.223554
Epoch 3980 of 5000 | Training Loss     0.138092 | Validation Loss     0.226965
Epoch 4000 of 5000 | Training Loss     0.136303 | Validation Loss     0.220792
Epoch 4020 of 5000 | Training Loss     0.133290 | Validation Loss     0.221382
Epoch 4040 of 5000 | Training Loss     0.135567 | Validation Loss     0.219660
Epoch 4060 of 5000 | Training Loss     0.137761 | Validation Loss     0.216880
Epoch 4080 of 5000 | Training Loss     0.137664 | Validation Loss     0.221260
Epoch 4100 of 5000 | Training Loss     0.135568 | Validation Loss     0.215873
Epoch 4120 of 5000 | Training Loss     0.138557 | Validation Loss     0.223182
Epoch 4140 of 5000 | Training Loss     0.138614 | Validation Loss     0.214849
Epoch 4160 of 5000 | Training Loss     0.134212 | Validation Loss     0.221176
Epoch 4180 of 5000 | Training Loss     0.134239 | Validation Loss     0.218119
Epoch 4200 of 5000 | Training Loss     0.139183 | Validation Loss     0.221815
Epoch 4220 of 5000 | Training Loss     0.135218 | Validation Loss     0.219385
Epoch 4240 of 5000 | Training Loss     0.134090 | Validation Loss     0.224633
Epoch 4260 of 5000 | Training Loss     0.137868 | Validation Loss     0.223902
Epoch 4280 of 5000 | Training Loss     0.135290 | Validation Loss     0.217157
Epoch 4300 of 5000 | Training Loss     0.133950 | Validation Loss     0.222214
Epoch 4320 of 5000 | Training Loss     0.137376 | Validation Loss     0.216033
Epoch 4340 of 5000 | Training Loss     0.134289 | Validation Loss     0.220154
Epoch 4360 of 5000 | Training Loss     0.138286 | Validation Loss     0.225840
Epoch 4380 of 5000 | Training Loss     0.133761 | Validation Loss     0.217640
Epoch 4400 of 5000 | Training Loss     0.135114 | Validation Loss     0.216726
Epoch 4420 of 5000 | Training Loss     0.138481 | Validation Loss     0.219672
Epoch 4440 of 5000 | Training Loss     0.136978 | Validation Loss     0.216889
Epoch 4460 of 5000 | Training Loss     0.134732 | Validation Loss     0.223950
Epoch 4480 of 5000 | Training Loss     0.132565 | Validation Loss     0.226152
Epoch 4500 of 5000 | Training Loss     0.136530 | Validation Loss     0.216229
Epoch 4520 of 5000 | Training Loss     0.135017 | Validation Loss     0.222252
Epoch 4540 of 5000 | Training Loss     0.135793 | Validation Loss     0.220057
Epoch 4560 of 5000 | Training Loss     0.137700 | Validation Loss     0.218895
Epoch 4580 of 5000 | Training Loss     0.134800 | Validation Loss     0.226011
Epoch 4600 of 5000 | Training Loss     0.139165 | Validation Loss     0.214006
Epoch 4620 of 5000 | Training Loss     0.137652 | Validation Loss     0.217016
Epoch 4640 of 5000 | Training Loss     0.136503 | Validation Loss     0.221651
Epoch 4660 of 5000 | Training Loss     0.137082 | Validation Loss     0.218623
Epoch 4680 of 5000 | Training Loss     0.134090 | Validation Loss     0.230526
Epoch 4700 of 5000 | Training Loss     0.136060 | Validation Loss     0.218616
Epoch 4720 of 5000 | Training Loss     0.140340 | Validation Loss     0.218326
Epoch 4740 of 5000 | Training Loss     0.132578 | Validation Loss     0.219336
Epoch 4760 of 5000 | Training Loss     0.137077 | Validation Loss     0.221903
Epoch 4780 of 5000 | Training Loss     0.134838 | Validation Loss     0.222159
Epoch 4800 of 5000 | Training Loss     0.135003 | Validation Loss     0.220038
Epoch 4820 of 5000 | Training Loss     0.137041 | Validation Loss     0.217420
Epoch 4840 of 5000 | Training Loss     0.136816 | Validation Loss     0.219639
Epoch 4860 of 5000 | Training Loss     0.132324 | Validation Loss     0.218044
Epoch 4880 of 5000 | Training Loss     0.134342 | Validation Loss     0.219052
Epoch 4900 of 5000 | Training Loss     0.134339 | Validation Loss     0.221846
Epoch 4920 of 5000 | Training Loss     0.135797 | Validation Loss     0.217714
Epoch 4940 of 5000 | Training Loss     0.134002 | Validation Loss     0.222817
Epoch 4960 of 5000 | Training Loss     0.136970 | Validation Loss     0.221305
Epoch 4980 of 5000 | Training Loss     0.132139 | Validation Loss     0.220243
COL_Y ['Id', 'Iq', 'Idc']
Train time: 8070.68, Recent loss: 0.133903, RMS Errors: 0.2002 0.1353 0.0221
                          MAE Errors: 0.1538 0.0996 0.0135

