C:\src\pecblocks\examples\hwpv>python pv3_training.py ./unb3/unb3_config.json c:/data/unb3.hdf5
model_folder = ./unb3
model_root = unb3
data_path = c:/data/unb3.hdf5
idx_in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
idx_out [14, 15, 16, 17, 18, 19, 20, 21]
read 2430 dataframes
dt=0.002000 data_len=3500 n_io=22 n_case=2430
['T', 'G', 'Fc', 'Md', 'Mq', 'Vdlo', 'Vqlo', 'V0lo', 'Vdhi', 'Vqhi', 'V0hi', 'GVlo', 'Ctl', 'Unb'] ['Vdc', 'Idc', 'Idlo', 'Iqlo', 'I0lo', 'Idhi', 'Iqhi', 'I0hi'] (2430, 3500, 22)
shapes of t (3500,) data_train (2430, 3500, 22) n_in=14, n_out=8
t range 0.000000 to 6.998000
Before Scaling:
Column       Min       Max      Mean     Range
T         35.000    35.003    35.001     0.003
G         -0.000   950.095   491.181   950.095
Fc        57.500    62.506    60.003     5.006
Md         0.900     1.000     0.950     0.100
Mq        -0.300     0.300     0.000     0.600
Vdlo      -0.373   326.597   179.571   326.971
Vqlo    -102.763    94.298    -2.358   197.060
V0lo      -0.020     0.035    -0.000     0.054
Vdhi       0.000     4.477     0.524     4.477
Vqhi      -0.000     1.490     0.127     1.490
V0hi      -0.003     0.309     0.042     0.312
GVlo      -0.000   380.038   138.060   380.038
Ctl        0.000     1.000     0.714     1.000
Unb        0.000     1.000     0.428     1.000
Vdc       -0.000   184.742    95.381   184.742
Idc       -0.000   280.474   144.863   280.474
Idlo      -0.141   106.202    47.707   106.343
Iqlo     -35.351    29.315    -1.049    64.666
I0lo      -0.563     0.341    -0.000     0.905
Idhi      -0.083     8.334     1.128     8.417
Iqhi      -0.179     8.595     1.117     8.774
I0hi      -0.163     8.304     1.145     8.467
After Scaling:
Column       Min       Max      Mean     Range     Scale    Offset
T         -0.462     0.538    -0.041     1.000     0.003    35.001
G         -0.517     0.483     0.000     1.000   950.095   491.181
Fc        -0.500     0.500    -0.000     1.000     5.006    60.003
Md        -0.500     0.500    -0.000     1.000     0.100     0.950
Mq        -0.501     0.499    -0.000     1.000     0.600     0.000
Vdlo      -0.550     0.450     0.000     1.000   326.971   179.571
Vqlo      -0.510     0.490     0.000     1.000   197.060    -2.358
V0lo      -0.362     0.638     0.000     1.000     0.054    -0.000
Vdhi      -0.117     0.883     0.000     1.000     4.477     0.524
Vqhi      -0.085     0.915     0.000     1.000     1.490     0.127
V0hi      -0.144     0.856     0.000     1.000     0.312     0.042
GVlo      -0.363     0.637    -0.000     1.000   380.038   138.060
Ctl       -0.714     0.286    -0.000     1.000     1.000     0.714
Unb       -0.428     0.572     0.000     1.000     1.000     0.428
Vdc       -0.516     0.484    -0.000     1.000   184.742    95.381
Idc       -0.516     0.484    -0.000     1.000   280.474   144.863
Idlo      -0.450     0.550     0.000     1.000   106.343    47.707
Iqlo      -0.530     0.470    -0.000     1.000    64.666    -1.049
I0lo      -0.623     0.377    -0.000     1.000     0.905    -0.000
Idhi      -0.144     0.856    -0.000     1.000     8.417     1.128
Iqhi      -0.148     0.852     0.000     1.000     8.774     1.117
I0hi      -0.154     0.846     0.000     1.000     8.467     1.145
make_mimo_block iir
Dataset split: 2430 2187 243 validation_scale=9.000
Epoch    0 of 1000 | Training Loss     2.245650 | Validation Loss     0.742514
Epoch   10 of 1000 | Training Loss     0.015862 | Validation Loss     0.015090
Epoch   20 of 1000 | Training Loss     0.008759 | Validation Loss     0.009148
Epoch   30 of 1000 | Training Loss     0.006713 | Validation Loss     0.007001
Epoch   40 of 1000 | Training Loss     0.005780 | Validation Loss     0.005804
Epoch   50 of 1000 | Training Loss     0.005184 | Validation Loss     0.005463
Epoch   60 of 1000 | Training Loss     0.004660 | Validation Loss     0.004368
Epoch   70 of 1000 | Training Loss     0.004110 | Validation Loss     0.003894
Epoch   80 of 1000 | Training Loss     0.003688 | Validation Loss     0.003958
Epoch   90 of 1000 | Training Loss     0.003484 | Validation Loss     0.003883
Epoch  100 of 1000 | Training Loss     0.003317 | Validation Loss     0.003439
Epoch  110 of 1000 | Training Loss     0.003008 | Validation Loss     0.003188
Epoch  120 of 1000 | Training Loss     0.002991 | Validation Loss     0.003070
Epoch  130 of 1000 | Training Loss     0.002685 | Validation Loss     0.002826
Epoch  140 of 1000 | Training Loss     0.002812 | Validation Loss     0.003623
Epoch  150 of 1000 | Training Loss     0.003048 | Validation Loss     0.002963
Epoch  160 of 1000 | Training Loss     0.002364 | Validation Loss     0.003018
Epoch  170 of 1000 | Training Loss     0.002914 | Validation Loss     0.002527
Epoch  180 of 1000 | Training Loss     0.002198 | Validation Loss     0.002651
Epoch  190 of 1000 | Training Loss     0.002074 | Validation Loss     0.002694
Epoch  200 of 1000 | Training Loss     0.002367 | Validation Loss     0.002929
Epoch  210 of 1000 | Training Loss     0.001920 | Validation Loss     0.002149
Epoch  220 of 1000 | Training Loss     0.001845 | Validation Loss     0.001857
Epoch  230 of 1000 | Training Loss     0.001597 | Validation Loss     0.001568
Epoch  240 of 1000 | Training Loss     0.001962 | Validation Loss     0.001942
Epoch  250 of 1000 | Training Loss     0.001918 | Validation Loss     0.001894
Epoch  260 of 1000 | Training Loss     0.001590 | Validation Loss     0.001621
Epoch  270 of 1000 | Training Loss     0.001565 | Validation Loss     0.001819
Epoch  280 of 1000 | Training Loss     0.001953 | Validation Loss     0.001487
Epoch  290 of 1000 | Training Loss     0.001550 | Validation Loss     0.001504
Epoch  300 of 1000 | Training Loss     0.001568 | Validation Loss     0.001503
Epoch  310 of 1000 | Training Loss     0.001354 | Validation Loss     0.001645
Epoch  320 of 1000 | Training Loss     0.001577 | Validation Loss     0.004700
Epoch  330 of 1000 | Training Loss     0.001523 | Validation Loss     0.002784
Epoch  340 of 1000 | Training Loss     0.001246 | Validation Loss     0.001283
Epoch  350 of 1000 | Training Loss     0.001226 | Validation Loss     0.001221
Epoch  360 of 1000 | Training Loss     0.001264 | Validation Loss     0.001368
Epoch  370 of 1000 | Training Loss     0.001475 | Validation Loss     0.001686
Epoch  380 of 1000 | Training Loss     0.001229 | Validation Loss     0.001549
Epoch  390 of 1000 | Training Loss     0.001536 | Validation Loss     0.001842
Epoch  400 of 1000 | Training Loss     0.001248 | Validation Loss     0.001454
Epoch  410 of 1000 | Training Loss     0.001248 | Validation Loss     0.001279
Epoch  420 of 1000 | Training Loss     0.001114 | Validation Loss     0.001224
Epoch  430 of 1000 | Training Loss     0.001215 | Validation Loss     0.001124
Epoch  440 of 1000 | Training Loss     0.001301 | Validation Loss     0.001284
Epoch  450 of 1000 | Training Loss     0.001123 | Validation Loss     0.001239
Epoch  460 of 1000 | Training Loss     0.001294 | Validation Loss     0.001452
Epoch  470 of 1000 | Training Loss     0.001625 | Validation Loss     0.001602
Epoch  480 of 1000 | Training Loss     0.001605 | Validation Loss     0.001558
Epoch  490 of 1000 | Training Loss     0.001160 | Validation Loss     0.001500
Epoch  500 of 1000 | Training Loss     0.001113 | Validation Loss     0.001124
Epoch  510 of 1000 | Training Loss     0.001076 | Validation Loss     0.001415
Epoch  520 of 1000 | Training Loss     0.001325 | Validation Loss     0.002435
Epoch  530 of 1000 | Training Loss     0.001045 | Validation Loss     0.001011
Epoch  540 of 1000 | Training Loss     0.001027 | Validation Loss     0.001113
Epoch  550 of 1000 | Training Loss     0.001237 | Validation Loss     0.001435
Epoch  560 of 1000 | Training Loss     0.001228 | Validation Loss     0.001074
Epoch  570 of 1000 | Training Loss     0.001164 | Validation Loss     0.001150
Epoch  580 of 1000 | Training Loss     0.001121 | Validation Loss     0.001167
Epoch  590 of 1000 | Training Loss     0.001109 | Validation Loss     0.001458
Epoch  600 of 1000 | Training Loss     0.001082 | Validation Loss     0.000971
Epoch  610 of 1000 | Training Loss     0.001019 | Validation Loss     0.001382
Epoch  620 of 1000 | Training Loss     0.001098 | Validation Loss     0.001129
Epoch  630 of 1000 | Training Loss     0.001263 | Validation Loss     0.001153
Epoch  640 of 1000 | Training Loss     0.001230 | Validation Loss     0.001379
Epoch  650 of 1000 | Training Loss     0.001134 | Validation Loss     0.001231
Epoch  660 of 1000 | Training Loss     0.001209 | Validation Loss     0.001067
Epoch  670 of 1000 | Training Loss     0.000940 | Validation Loss     0.000983
Epoch  680 of 1000 | Training Loss     0.000964 | Validation Loss     0.000946
Epoch  690 of 1000 | Training Loss     0.001426 | Validation Loss     0.001061
Epoch  700 of 1000 | Training Loss     0.001170 | Validation Loss     0.001680
Epoch  710 of 1000 | Training Loss     0.000922 | Validation Loss     0.001072
Epoch  720 of 1000 | Training Loss     0.002555 | Validation Loss     0.001063
Epoch  730 of 1000 | Training Loss     0.000882 | Validation Loss     0.001005
Epoch  740 of 1000 | Training Loss     0.000923 | Validation Loss     0.000877
Epoch  750 of 1000 | Training Loss     0.001039 | Validation Loss     0.001141
Epoch  760 of 1000 | Training Loss     0.000829 | Validation Loss     0.000956
Epoch  770 of 1000 | Training Loss     0.002090 | Validation Loss     0.001226
Epoch  780 of 1000 | Training Loss     0.000825 | Validation Loss     0.001035
Epoch  790 of 1000 | Training Loss     0.001260 | Validation Loss     0.000882
Epoch  800 of 1000 | Training Loss     0.000898 | Validation Loss     0.001311
Epoch  810 of 1000 | Training Loss     0.000936 | Validation Loss     0.001126
Epoch  820 of 1000 | Training Loss     0.000825 | Validation Loss     0.000958
Epoch  830 of 1000 | Training Loss     0.001004 | Validation Loss     0.001275
Epoch  840 of 1000 | Training Loss     0.000861 | Validation Loss     0.001035
Epoch  850 of 1000 | Training Loss     0.000980 | Validation Loss     0.000883
Epoch  860 of 1000 | Training Loss     0.001117 | Validation Loss     0.001109
Epoch  870 of 1000 | Training Loss     0.001098 | Validation Loss     0.001103
Epoch  880 of 1000 | Training Loss     0.000848 | Validation Loss     0.000854
Epoch  890 of 1000 | Training Loss     0.000795 | Validation Loss     0.000994
Epoch  900 of 1000 | Training Loss     0.000891 | Validation Loss     0.000796
Epoch  910 of 1000 | Training Loss     0.000808 | Validation Loss     0.000880
Epoch  920 of 1000 | Training Loss     0.000769 | Validation Loss     0.000802
Epoch  930 of 1000 | Training Loss     0.000797 | Validation Loss     0.000980
Epoch  940 of 1000 | Training Loss     0.000792 | Validation Loss     0.000742
Epoch  950 of 1000 | Training Loss     0.000799 | Validation Loss     0.000951
Epoch  960 of 1000 | Training Loss     0.000892 | Validation Loss     0.000933
Epoch  970 of 1000 | Training Loss     0.001412 | Validation Loss     0.000868
Epoch  980 of 1000 | Training Loss     0.000808 | Validation Loss     0.000830
Epoch  990 of 1000 | Training Loss     0.000868 | Validation Loss     0.000866
COL_Y ['Vdc', 'Idc', 'Idlo', 'Iqlo', 'I0lo', 'Idhi', 'Iqhi', 'I0hi']
Train time: 86653.18, Recent loss: 0.000811, RMS Errors: 0.0141 0.0070 0.0106 0.0044 0.0027 0.0056 0.0049 0.0038
                          MAE Errors: 0.0039 0.0024 0.0043 0.0023 0.0013 0.0027 0.0026 0.0017
